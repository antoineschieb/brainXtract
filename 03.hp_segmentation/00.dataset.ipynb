{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np \n",
    "from collections import OrderedDict\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.helper import convert_nrrd_to_nifti, create_folder, plot_all_slices, plot_histogram, generate_binary_image, adjust_affine_for_spacing_and_origin, save_binary_image_with_adjusted_origin, make_if_dont_exist\n",
    "from utils.metrics import dice_score_per_class, hausdorff_distance_per_class, ravd_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset path\n",
    "BASE_PATH = Path('./').resolve()\n",
    "DATA_PATH = BASE_PATH / 'dataset'\n",
    "\n",
    "project_name = 'HPC' #change here for different task name\n",
    "task_name = 'Dataset003_' + project_name \n",
    "\n",
    "TRAINING_DATASET_PATH = BASE_PATH / 'dataset/nnUNet_raw_data' / task_name / 'imagesTr'\n",
    "GT_TRAINING_DATASET_PATH = BASE_PATH / 'dataset/nnUNet_raw_data' / task_name / 'labelsTr'\n",
    "TEST_DATASET_PATH = BASE_PATH / 'dataset/nnUNet_raw_data' / task_name / 'imagesTs'\n",
    "GT_TEST_DATASET_PATH = BASE_PATH / 'dataset/nnUNet_raw_data' / task_name / 'labelsTs'\n",
    "PREDICTION_RESULTS_PATH  = BASE_PATH / 'dataset/nnUNet_Prediction_Results' / task_name\n",
    "TASK_PATH = BASE_PATH / 'dataset/nnUNet_raw_data' / task_name \n",
    "\n",
    "# setup environment variables\n",
    "nnUNet_raw = BASE_PATH / 'dataset/nnUNet_raw_data'\n",
    "nnUNet_preprocessed = BASE_PATH / 'dataset/nnUNet_preprocessed'\n",
    "nnUNet_results = BASE_PATH / 'dataset/nnUNet_results'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_if_dont_exist(TRAINING_DATASET_PATH,overwrite=False)\n",
    "make_if_dont_exist(GT_TRAINING_DATASET_PATH)\n",
    "make_if_dont_exist(TEST_DATASET_PATH)\n",
    "make_if_dont_exist(GT_TEST_DATASET_PATH)\n",
    "make_if_dont_exist(PREDICTION_RESULTS_PATH)\n",
    "\n",
    "make_if_dont_exist(nnUNet_preprocessed)\n",
    "make_if_dont_exist(nnUNet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import json\n",
    "from os.path import join\n",
    "\n",
    "def save_json(data, file_path, sort_keys=False):\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4, sort_keys=sort_keys)\n",
    "\n",
    "def generate_dataset_json(output_folder: str,\n",
    "                          channel_names: dict,\n",
    "                          labels: dict,\n",
    "                          num_training_cases: int,\n",
    "                          file_ending: str,\n",
    "                          regions_class_order: Tuple[int, ...] = None,\n",
    "                          dataset_name: str = None, reference: str = None, release: str = None, license: str = None,\n",
    "                          description: str = None,\n",
    "                          overwrite_image_reader_writer: str = None, **kwargs):\n",
    "    \n",
    "    has_regions: bool = any([isinstance(i, (tuple, list)) and len(i) > 1 for i in labels.values()])\n",
    "    if has_regions:\n",
    "        assert regions_class_order is not None, f\"You have defined regions but regions_class_order is not set. \" \\\n",
    "                                                f\"You need that.\"\n",
    "    # channel names need strings as keys\n",
    "    keys = list(channel_names.keys())\n",
    "    for k in keys:\n",
    "        if not isinstance(k, str):\n",
    "            channel_names[str(k)] = channel_names[k]\n",
    "            del channel_names[k]\n",
    "\n",
    "    # labels need ints as values\n",
    "    for l in labels.keys():\n",
    "        value = labels[l]\n",
    "        if isinstance(value, (tuple, list)):\n",
    "            value = tuple([int(i) for i in value])\n",
    "            labels[l] = value\n",
    "        else:\n",
    "            labels[l] = int(labels[l])\n",
    "\n",
    "    dataset_json = {\n",
    "        'channel_names': channel_names,  # previously this was called 'modality'. I didn't like this so this is\n",
    "        # channel_names now. Live with it.\n",
    "        'labels': labels,\n",
    "        'numTraining': num_training_cases,\n",
    "        'file_ending': file_ending,\n",
    "    }\n",
    "\n",
    "    if dataset_name is not None:\n",
    "        dataset_json['name'] = dataset_name\n",
    "    if reference is not None:\n",
    "        dataset_json['reference'] = reference\n",
    "    if release is not None:\n",
    "        dataset_json['release'] = release\n",
    "    if license is not None:\n",
    "        dataset_json['licence'] = license\n",
    "    if description is not None:\n",
    "        dataset_json['description'] = description\n",
    "    if overwrite_image_reader_writer is not None:\n",
    "        dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "    if regions_class_order is not None:\n",
    "        dataset_json['regions_class_order'] = regions_class_order\n",
    "\n",
    "    dataset_json.update(kwargs)\n",
    "\n",
    "    save_json(dataset_json, join(output_folder, 'dataset.json'), sort_keys=False)\n",
    "    \n",
    "\n",
    "# List all files in the training images and labels directories\n",
    "image_files = os.listdir(TRAINING_DATASET_PATH)\n",
    "label_files = os.listdir(GT_TRAINING_DATASET_PATH)\n",
    "test_ids = os.listdir(TEST_DATASET_PATH)\n",
    "\n",
    "channel_names = {\"0\": \"microscopic\"}\n",
    "num_training_cases = len(image_files)  \n",
    "file_ending = \".nii.gz\"\n",
    "\n",
    "generate_dataset_json(\n",
    "    output_folder=TASK_PATH,\n",
    "    channel_names=channel_names,\n",
    "    labels={\"background\":0, \"Hippocampus\":1},\n",
    "    num_training_cases=num_training_cases,\n",
    "    file_ending=file_ending,\n",
    "    dataset_name=\"Mouse Brain Segmentation\",\n",
    "    description=\"Mouse Brain Segmentation\",\n",
    "    reference=\"\",\n",
    "    release=\"0.0\",\n",
    "    license=\"\",\n",
    "    training = [{'image': f\"./imagesTr/{image_file}\", 'label': f\"./labelsTr/{label_file}\"} \n",
    "            for image_file, label_file in zip(sorted(image_files), sorted(label_files))],\n",
    "    test=[\"./imagesTs/%s\" % (i[:i.find(\"_0000\")] + '.nii.gz') for i in test_ids]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
